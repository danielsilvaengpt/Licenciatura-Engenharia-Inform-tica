### --- 1. IMPORTAﾃﾃグ DE BIBLIOTECAS ---
import numpy as np
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
from Functions.pso import pso


base_drive_path = r"C:\Users\Daniel\Desktop\3_ano\IC\TP\Dataset\Skin_Diseases\kaggle"
train_otimization_path = os.path.join(base_drive_path, "temp_train")
val_path = os.path.join(base_drive_path, "val")

# --- 2. CONFIGURAﾃﾃグ DOS GERADORES ---
IMG_SIZE_OPT = 64
IMG_SIZE_FINAL = 128
batch_size = 16

print(f"A carregar gerador de treino de otimizaﾃｧﾃ｣o (temp_train, {IMG_SIZE_OPT}x{IMG_SIZE_OPT})...")
trainWSA_datagen = ImageDataGenerator(rescale=1. / 255, fill_mode='nearest')
trainWSA_generator = trainWSA_datagen.flow_from_directory(
    train_otimization_path,
    target_size=(IMG_SIZE_OPT, IMG_SIZE_OPT),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

print(f"A carregar gerador de validaﾃｧﾃ｣o de otimizaﾃｧﾃ｣o (val, {IMG_SIZE_OPT}x{IMG_SIZE_OPT})...")
val_opt_datagen = ImageDataGenerator(rescale=1. / 255)
val_generator_opt = val_opt_datagen.flow_from_directory(
    val_path,
    target_size=(IMG_SIZE_OPT, IMG_SIZE_OPT),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

num_classes = trainWSA_generator.num_classes


### --- 3. FUNﾃﾃグ PARA CRIAR O MODELO ---
def create_model(learning_rate, num_neurons, size):
    model = models.Sequential([
        layers.Conv2D(16, (3, 3), activation='relu', input_shape=(size, size, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(int(num_neurons), activation='relu'),
        layers.Dense(num_classes, activation='softmax')
    ])
    optimizer = Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    return model


### --- 4. DEFINIﾃﾃグ DA FUNﾃﾃグ DE FITNESS (Melhorada) ---
# Aumentei o limite para 20, mas o EarlyStopping vai parar muito antes se necessﾃ｡rio
EPOCHS_FOR_OPTIMIZATION = 10


def fitness_function(params):
    learning_rate = params[0]
    num_neurons = int(params[1])

    # --- ALTERAﾃﾃグ 1: Adicionado EarlyStopping ---

    print(f"Testando: LR={learning_rate:.6f}, Neurﾃｳnios={num_neurons}...", end=" ")

    model = create_model(learning_rate, num_neurons, IMG_SIZE_OPT)
    history = model.fit(
        trainWSA_generator,
        epochs=EPOCHS_FOR_OPTIMIZATION,
        validation_data=val_generator_opt,
        verbose=0
    )

    val_loss = np.min(history.history['val_loss'])
    epochs_run = len(history.history['val_loss'])  # Para sabermos quantas ﾃｩpocas durou
    print(f"-> Val Loss={val_loss:.5f} ({epochs_run} ﾃｩpocas)")

    return val_loss


### --- 5. EXECUﾃﾃグ DA OTIMIZAﾃﾃグ SWARM (APENAS PSO) ---
n_agentes = 5
n_iteracoes = 10
lb = [0.0001, 32]
ub = [0.01, 128]

print("\n" + "=" * 50)
print("--- INICIANDO OTIMIZAﾃﾃグ DE HIPERPARﾃMETROS (PSO) ---")
print(f"Algoritmo usarﾃ｡ {n_agentes} agentes e {n_iteracoes} iteraﾃｧﾃｵes.")
print("=" * 50 + "\n")

print("\n--- Executando Particle Swarm Optimization (PSO) ---")
pso_optimizer = pso(n=n_agentes, function=fitness_function, lb=lb, ub=ub, dimension=2, iteration=n_iteracoes)

print("\nA obter a melhor soluﾃｧﾃ｣o do PSO...")
best_params_pso = pso_optimizer.get_Gbest()

best_fitness_pso = pso_optimizer.get_Gbest_fitness()
print("(Score recuperado da memﾃｳria - SEM re-treino desnecessﾃ｡rio)")


print("--- OTIMIZAﾃﾃグ PSO CONCLUﾃ好A ---")
print(f"醇 Melhor Val Loss (PSO): {best_fitness_pso:.5f}")
print(f"畠 Melhores Hiperparﾃ｢metros (PSO):")
print(f"Learning Rate: {best_params_pso[0]:.6f}")
print(f"Neurﾃｳnios: {int(best_params_pso[1])}")
print("--- Script Concluﾃｭdo ---")